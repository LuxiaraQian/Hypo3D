[submodule "2D-VLM/Qwen2-VL/flash-attention"]
	path = 2D-VLM/Qwen2-VL/flash-attention
	url = https://github.com/Dao-AILab/flash-attention.git
